{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import importlib\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_forecasting import Baseline, NHiTS, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import RMSE, MAE, SMAPE\n",
    "\n",
    "import config\n",
    "import db\n",
    "import fetcher\n",
    "import model\n",
    "import strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_predictions(\n",
    "    cfg: config.BaseConfig, \n",
    "    nhits: NHiTS,\n",
    "    val_df: pd.DataFrame,\n",
    "    train_dataset: TimeSeriesDataSet,\n",
    "    group_id: str,\n",
    "    context_length: int,\n",
    "    prediction_length: int\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Step through the validation set and make a prediction at each step using context_length.\n",
    "\n",
    "    Args:\n",
    "        cfg: BaseConfig.\n",
    "        nhits: Trained NHiTS model.\n",
    "        val_df: DataFrame with validation data.\n",
    "        train_dataset: Original training TimeSeriesDataSet for metadata reuse.\n",
    "        group_id: Which group to run predictions on (as string).\n",
    "        context_length: Number of time steps used as model input.\n",
    "        predictions_length\n",
    "\n",
    "    Returns:\n",
    "        List of (time_idx, prediction) tuples.\n",
    "    \"\"\"\n",
    "    conn, cur = db.connect_to_db()\n",
    "    cash, stocks = strategy.get_account_data(cur, cfg.account_table)\n",
    "    num_buys = 0\n",
    "    num_sells = 0\n",
    "    closing_price = 0\n",
    "    df_group = val_df[val_df[\"group_id\"] == group_id].reset_index(drop=True)\n",
    "    results = [] # tidx, predicted value at tidx + 1, currentPrice at tidx - predicted value at tidx + 1, accountValue after trade, action from trade\n",
    "\n",
    "    max_idx = len(df_group) - context_length + 1\n",
    "\n",
    "    for i in range(max_idx):\n",
    "        context_df = df_group.iloc[i : i + context_length].copy()\n",
    "        pred_value = model.make_prediction(nhits, context_df, train_dataset, prediction_length)\n",
    "        prediction_time_idx = context_df.iloc[-1][\"time_idx\"]\n",
    "        closing_price= context_df.iloc[-1][\"currentPrice\"]\n",
    "        cash, stocks, action = strategy.trade(closing_price, pred_value, cash, stocks)\n",
    "        if action == \"bought\":\n",
    "            num_buys += 1\n",
    "        else:\n",
    "            num_sells += 1\n",
    "        accountValue = cash + stocks*closing_price\n",
    "        results.append((prediction_time_idx, pred_value, closing_price - pred_value, accountValue, action))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(results, val_df)->float:\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results, columns=[\"time_idx\", \"predicted\", \"vsCurrent\", \"accountValue\", \"action\"])\n",
    "    results_df[\"time_idx\"] = results_df[\"time_idx\"].astype(int)\n",
    "\n",
    "    # Shift prediction time to match the actual it is predicting\n",
    "    results_df[\"predicted_time_idx\"] = results_df[\"time_idx\"] + 1\n",
    "\n",
    "    # Filter val_df for the correct group\n",
    "    val_group = val_df[val_df[\"group_id\"] == \"0\"].copy()\n",
    "    val_group = val_group.drop_duplicates(subset=[\"time_idx\"])\n",
    "\n",
    "    # Merge using shifted time index\n",
    "    comparison_df = pd.merge(\n",
    "        results_df,\n",
    "        val_group[[\"time_idx\", \"currentPrice\"]],\n",
    "        left_on=\"predicted_time_idx\",\n",
    "        right_on=\"time_idx\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_pred\", \"_actual\")\n",
    "    )\n",
    "\n",
    "    # Optional comparison\n",
    "    comparison_df[\"error\"] = comparison_df[\"predicted\"] - comparison_df[\"currentPrice\"]\n",
    "    comparison_df[\"above_actual\"] = comparison_df[\"error\"] > 0\n",
    "    comparison_df[\"below_input\"]=comparison_df[\"vsCurrent\"] > 0\n",
    "\n",
    "    # Compute comparison\n",
    "    comparison_df[\"vsNextCurrentPrice\"] = comparison_df[\"error\"].apply(\n",
    "        lambda x: \"above\" if x > 0 else (\"below\" if x < 0 else \"equal\")\n",
    "    )\n",
    "    comparison_df[\"vsCurrentPrice\"] = comparison_df[\"vsCurrent\"].apply(\n",
    "        lambda x: \"below\" if x > 0 else (\"above\" if x < 0 else \"equal\")\n",
    "    )\n",
    "\n",
    "    # Get percentage breakdown\n",
    "    percentages = comparison_df[\"vsNextCurrentPrice\"].value_counts(normalize=True) * 100\n",
    "    percentages_curr = comparison_df[\"vsCurrentPrice\"].value_counts(normalize=True) * 100\n",
    "    percentages_bought_sold = comparison_df[\"action\"].value_counts(normalize=True) * 100\n",
    "\n",
    "    offset = results_df[\"vsCurrent\"].mean()\n",
    "\n",
    "    print(percentages)\n",
    "    print(percentages_curr)\n",
    "    print(percentages_bought_sold)\n",
    "    print(offset)\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5312a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_groups(data: pd.DataFrame, time_col=\"time_idx\", value_col=\"currentPrice\", group_col=\"group_id\"):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for group_id, group_df in data.groupby(group_col):\n",
    "        plt.plot(group_df[time_col], group_df[value_col], label=f'Group {group_id}')\n",
    "    \n",
    "    plt.title(\"Time Series per Group\")\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.ylabel(value_col)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_over_time(predictions, value_col=\"currentPrice\"):\n",
    "    # Extract needed data\n",
    "    df_idx = predictions.index\n",
    "    true = predictions.y[0].view_as(predictions.output.prediction)\n",
    "    pred = predictions.output.prediction  # predicted values\n",
    "    grouped = df_idx.groupby(\"group_id\")\n",
    "    plt.figure(figsize=(28, 6))\n",
    "\n",
    "    for group_id, group_idx in grouped:\n",
    "        print(group_id)\n",
    "        print(group_idx.head(5))\n",
    "        print(group_idx.tail(5))\n",
    "        time_base = group_idx[\"time_idx\"].values\n",
    "\n",
    "        # Plot actual full true sequence (first step from each decoder target)\n",
    "        plt.plot(time_base, true[:, 0][group_idx.index], label=f\"True Group {group_id}\")\n",
    "\n",
    "        # Plot first prediction step\n",
    "        plt.plot(time_base, pred[:, 0][group_idx.index], linestyle=\"--\", label=f\"Pred Group {group_id}\")\n",
    "\n",
    "    plt.title(\"First Step-Ahead Predictions vs True Values\")\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.ylabel(value_col)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec81f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "importlib.reload(fetcher)\n",
    "importlib.reload(config)\n",
    "importlib.reload(db)\n",
    "importlib.reload(strategy)\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "test_config=config.get_test_config()\n",
    "prod_config=config.get_prod_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = db.connect_to_db()\n",
    "cc=np.float64(2330.34)\n",
    "strategy.write_account_data(conn, cur, cc, 0, np.float64(233.34), cc, 0, 0, test_config.account_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6faff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.disconnect_from_db(conn, cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef648cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stderr.write(f\"Starting model training at: {datetime.datetime.now(test_config.eastern)}\\n\")\n",
    "best_model_path, train_dataset, val_df=model.train_best_model(test_config)\n",
    "print(best_model_path)\n",
    "sys.stderr.write(f\"Completed model training at: {datetime.datetime.now(test_config.eastern)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = NHiTS.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fe517",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = rolling_predictions(test_config, best_model, val_df, train_dataset, \"1\", test_config.context_length, test_config.prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.rolling_predictions(best_model, val_df, train_dataset, \"1\", test_config.context_length, test_config.prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = model.analyze(results, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cur = db.connect_to_db()\n",
    "raw_data = db.fetch_data(cur, test_config.quote_table)\n",
    "processed_data=model.add_tidx_and_groupid(raw_data)\n",
    "train_df, val_df = model.construct_dataframes(processed_data)\n",
    "tvur, sr = model.split_columns_by_group_variation(processed_data)\n",
    "train_dataset, val_dataset=model.construct_datasets(train_df, val_df, tvur, sr, test_config.context_length, test_config.prediction_length)\n",
    "train_dataloader, val_dataloader = model.construct_dataloaders(train_dataset, val_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_groups(train_df)\n",
    "plot_all_groups(val_df)\n",
    "val_dataloader_pred = val_dataset.to_dataloader(train=False, batch_size=1, num_workers=8)\n",
    "baseline_predictions = Baseline().predict(val_dataloader_pred, trainer_kwargs={\"accelerator\": \"cpu\", \"logger\": False, \"enable_checkpointing\":False, \"enable_model_summary\":False, \"enable_progress_bar\":False}, return_y=True)\n",
    "y_true = baseline_predictions.y[0].view_as(baseline_predictions.output)\n",
    "print(SMAPE()(baseline_predictions.output, y_true))\n",
    "predictions= best_model.predict(val_dataloader_pred, mode=\"raw\", return_x=True, return_index=True, return_y=True, return_decoder_lengths=True, trainer_kwargs={\"accelerator\": \"cpu\", \"logger\": False, \"enable_checkpointing\":False, \"enable_model_summary\":False, \"enable_progress_bar\":False})\n",
    "predictions_y_true = predictions.y[0].view_as(predictions.output.prediction)\n",
    "print(SMAPE()(predictions.output.prediction.squeeze(-1), predictions_y_true.squeeze(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b03b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = best_model.predict(val_dataloader, mode=\"raw\", return_x=True, trainer_kwargs={\"accelerator\": \"cpu\", \"logger\": False, \"enable_checkpointing\":False, \"enable_model_summary\":False, \"enable_progress_bar\":False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(3):  # plot 10 examples\n",
    "    best_model.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
